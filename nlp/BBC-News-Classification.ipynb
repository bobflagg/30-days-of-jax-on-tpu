{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d44ab3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0468c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using jax 0.3.13\n",
      "Optax Version : 0.1.2\n",
      "Found 8 devices.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import jax\n",
    "from jax import numpy as jnp, random\n",
    "import numpy as np\n",
    "import optax\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "print(\"Using jax\", jax.__version__)\n",
    "print(\"Optax Version : {}\".format(optax.__version__))\n",
    "devices = jax.local_devices()\n",
    "print(f\"Found {len(devices)} devices.\")\n",
    "devices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44bb5c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97130c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BBC News train dataset of shape 2,002 x 2.\n",
      "Loaded BBC News test dataset of shape 223 x 2.\n"
     ]
    }
   ],
   "source": [
    "path = '/home/rflagg/data/BBC-News/train-df.csv'\n",
    "train_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded BBC News train dataset of shape {train_df.shape[0]:,d} x {train_df.shape[1]:,d}.\")\n",
    "\n",
    "path = '/home/rflagg/data/BBC-News/test-df.csv'\n",
    "test_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded BBC News test dataset of shape {test_df.shape[0]:,d} x {test_df.shape[1]:,d}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af7dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "category2label = {\n",
    "    'business':0,\n",
    "    'entertainment':1,\n",
    "    'politics':2,\n",
    "    'sport':3,\n",
    "    'tech':4\n",
    "}\n",
    "train_df['label'] = [category2label[category] for category in train_df.category.values]\n",
    "path = '/home/rflagg/data/BBC-News/train-df.csv'\n",
    "train_df.to_csv(path, index=False)\n",
    "\n",
    "test_df['label'] = [category2label[category] for category in test_df.category.values]\n",
    "path = '/home/rflagg/data/BBC-News/test-df.csv'\n",
    "test_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45597c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            460\n",
       "business         459\n",
       "politics         375\n",
       "tech             361\n",
       "entertainment    347\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14eb87",
   "metadata": {},
   "source": [
    "# Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719fc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, FlaxAutoModelForSequenceClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d7c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    nb_epochs = 5\n",
    "    lr = 2e-5\n",
    "    per_device_bs = 8\n",
    "    num_labels = 5\n",
    "    model_name = 'bert-base-uncased'\n",
    "    total_batch_size = per_device_bs * jax.local_device_count()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "CONFIG = dict(\n",
    "    lr=2e-5,\n",
    "    model_name = 'bert-base-uncased',\n",
    "    epochs = 5,\n",
    "    split = 0.10,\n",
    "    per_device_bs = 8,\n",
    "    seed = 42,\n",
    "    num_labels = 2,\n",
    "    infra = \"Kaggle\",\n",
    "    competition = 'none',\n",
    "    _wandb_kernel = 'tanaym'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dd49f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_acc(preds, labels):\n",
    "    assert len(preds) == len(labels), \"Predictions and Labels matrices must be of same length\"\n",
    "    acc = (preds == labels).sum() / len(preds)\n",
    "    return acc\n",
    "\n",
    "class ACCURACY(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=\"Calculates Accuracy metric.\",\n",
    "            citation=\"TODO: _CITATION\",\n",
    "            inputs_description=\"_KWARGS_DESCRIPTION\",\n",
    "            features=datasets.Features({\n",
    "                'predictions': datasets.Value('int64'),\n",
    "                'references': datasets.Value('int64'),\n",
    "            }),\n",
    "            codebase_urls=[],\n",
    "            reference_urls=[],\n",
    "            format='numpy'\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references):\n",
    "        return {\"ACCURACY\": simple_acc(predictions, references)}\n",
    "    \n",
    "metric = ACCURACY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdce708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-94cc414e87dc0d8d\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/rflagg/.cache/huggingface/datasets/csv/default-94cc414e87dc0d8d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518f8c71870b4b289939ee3f34e41100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-8f8ca37f53b99530\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/rflagg/.cache/huggingface/datasets/csv/default-8f8ca37f53b99530/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7ecf97b3fe44ada9aa94203c652977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the training and testing files loaded in HF dataset format\n",
    "raw_train = load_dataset(\"csv\", data_files={'train': ['/home/rflagg/data/BBC-News/train-df.csv']})\n",
    "raw_test = load_dataset(\"csv\", data_files={'test': ['/home/rflagg/data/BBC-News/test-df.csv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee13889a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>worcester v sale (fri) sixways  friday  25 feb...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>sociedad set to rescue mladenovic rangers are ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>robots march to us cinema summit animated movi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>stam spices up man utd encounter ac milan defe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>campaigners attack mtv  sleaze  mtv has been c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  label\n",
       "0          sport  worcester v sale (fri) sixways  friday  25 feb...      3\n",
       "1          sport  sociedad set to rescue mladenovic rangers are ...      3\n",
       "2  entertainment  robots march to us cinema summit animated movi...      1\n",
       "3          sport  stam spices up man utd encounter ac milan defe...      3\n",
       "4  entertainment  campaigners attack mtv  sleaze  mtv has been c...      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "565e201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29854e63a0d84758a2410109483504b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a52f358be945228725e8e1c2b6f718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(data):\n",
    "    \"\"\"\n",
    "    Preprocessing function\n",
    "    \"\"\"\n",
    "    texts = (data[\"text\"],)\n",
    "    processed = Config.tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n",
    "    processed[\"labels\"] = data[\"label\"]\n",
    "    return processed\n",
    "\n",
    "train_dataset = raw_train.map(preprocess_function, batched=True, remove_columns=raw_train[\"train\"].column_names)\n",
    "test_dataset = raw_test.map(preprocess_function, batched=True, remove_columns=raw_test['test'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31df310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002 223\n"
     ]
    }
   ],
   "source": [
    "train = train_dataset['train']\n",
    "valid = test_dataset['test']\n",
    "print(len(train), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc098ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('classifier', 'bias'), ('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('classifier', 'kernel')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(Config.model_name, num_labels=Config.num_labels)\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(Config.model_name, config=config, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7939c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train steps (all the epochs) is 155\n"
     ]
    }
   ],
   "source": [
    "num_train_steps = len(train) // Config.total_batch_size * Config.nb_epochs\n",
    "learning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, peak_value=Config.lr, pct_start=0.1)\n",
    "print(\"The number of train steps (all the epochs) is\", num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccdd0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from typing import Callable\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from flax.training import train_state\n",
    "from flax import traverse_util\n",
    "import flax\n",
    "\n",
    "optimizer = optax.adamw(learning_rate=Config.lr, b1=0.9, b2=0.999, eps=1e-6, weight_decay=1e-2)\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    loss = optax.softmax_cross_entropy(logits, onehot(targets, num_classes=Config.num_labels))\n",
    "    return jnp.mean(loss)\n",
    "def eval_fn(logits):\n",
    "    return logits.argmax(-1)\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    eval_function: Callable = flax.struct.field(pytree_node=False)\n",
    "    loss_function: Callable = flax.struct.field(pytree_node=False)\n",
    "        \n",
    "state = TrainState.create(\n",
    "    apply_fn = model.__call__,\n",
    "    params = model.params,\n",
    "    tx = optimizer,\n",
    "    eval_function=eval_fn,\n",
    "    loss_function=loss_fn,\n",
    ")\n",
    "\n",
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "    \n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_fn(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = jax.lax.pmean({'loss': loss, 'learning_rate': learning_rate_function(state.step)}, axis_name='batch')\n",
    "    \n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aec453e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a7f3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.eval_function(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8a0b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91c9ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbcTrainDataLoader(rng, dataset, batch_size):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd2e72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbcEvalDataLoader(dataset, batch_size):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c330f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = flax.jax_utils.replicate(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a54dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49a53234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b170ab5ae0540fc8b76cabeb385d298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 | Train loss: 0.176 | Eval ACCURACY: 0.948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/5 | Train loss: 0.042 | Eval ACCURACY: 0.974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 | Train loss: 0.007 | Eval ACCURACY: 0.995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/5 | Train loss: 0.007 | Eval ACCURACY: 0.979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 | Train loss: 0.015 | Eval ACCURACY: 0.979\n"
     ]
    }
   ],
   "source": [
    "for i, epoch in enumerate(tqdm(range(1, Config.nb_epochs + 1), desc=f\"Epoch...\", position=0, leave=True)):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(total=len(train) // Config.total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "        for batch in bbcTrainDataLoader(input_rng, train, Config.total_batch_size):\n",
    "            state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(total=len(valid) // Config.total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "        for batch in bbcEvalDataLoader(valid, Config.total_batch_size):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = parallel_eval_step(state, batch)\n",
    "            metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n",
    "    eval_score = round(list(eval_metric.values())[0], 3)\n",
    "    metric_name = list(eval_metric.keys())[0]\n",
    "    \n",
    "    print(f\"{i+1}/{Config.nb_epochs} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c999d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efaa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "split_nb = int(len(df) * 0.10)\n",
    "\n",
    "test_df = df[:split_nb].reset_index(drop=True)\n",
    "train_df = df[split_nb:].reset_index(drop=True)\n",
    "\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-test-df.csv'\n",
    "test_df.to_csv(path, index=False)\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-train-df.csv'\n",
    "train_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-train-df.csv'\n",
    "train_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded HAM/SPAM train dataset of shape {train_df.shape[0]:,d} x {train_df.shape[1]:,d}.\")\n",
    "\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-test-df.csv'\n",
    "test_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded HAM/SPAM test dataset of shape {test_df.shape[0]:,d} x {test_df.shape[1]:,d}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30867cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ea1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = '/home/rflagg/data/ham-spam/SMSSpamCollection'\n",
    "df = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
    "with open(file_path) as f:\n",
    "  for line in f.readlines():\n",
    "    split = line.split('\\t')\n",
    "    df = df.append({'label': 1 if split[0] == 'spam' else 0,\n",
    "                    'text': split[1]},\n",
    "                    ignore_index = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9256216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d387c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/home/rflagg/data/training.1600000.processed.noemoticon.csv\"\n",
    "df = pd.read_csv(path, encoding='latin-1', names=['sentiment', 'id', 'date', 'query', 'username', 'text'])\n",
    "df = df[['sentiment', 'text']]\n",
    "df['sentiment'] = df['sentiment'].map({4: 1, 0: 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.sample(n=1).iloc[0]\n",
    "f\"[{x.sentiment}] {x.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_and_save(file_path: str, split: float = 0.10):\n",
    "    file = pd.read_csv(file_path, encoding='latin-1', names=['sentiment', 'id', 'date', 'query', 'username', 'text'])\n",
    "    file = file[['sentiment', 'text']]\n",
    "    file['sentiment'] = file['sentiment'].map({4: 1, 0: 0})\n",
    "    \n",
    "    file = file.sample(frac=1).reset_index(drop=True)\n",
    "    split_nb = int(len(file) * split)\n",
    "    \n",
    "    test_set = file[:split_nb].reset_index(drop=True)\n",
    "    train_set = file[split_nb:].reset_index(drop=True)\n",
    "    \n",
    "    train_set.to_csv(\"train_file.csv\", index=None)\n",
    "    test_set.to_csv(\"test_file.csv\", index=None)\n",
    "    print(\"Done.\")\n",
    "\n",
    "split_and_save(\"/home/rflagg/data/training.1600000.processed.noemoticon.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27622d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "request = requests.get(\"https://drive.google.com/uc?export=download&id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\")\n",
    "with open(\"data.zip\", \"wb\") as file:\n",
    "    file.write(request.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75b6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5087be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, stratify = df.category, test_size=1/10, random_state=42)\n",
    "path = '/home/rflagg/data/BBC-News/train-df.csv'\n",
    "train_df.to_csv(path, index=False)\n",
    "\n",
    "path = '/home/rflagg/data/BBC-News/test-df.csv'\n",
    "test_df.to_csv(path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
