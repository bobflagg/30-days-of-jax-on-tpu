{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d44ab3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0468c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  JAX Version: 0.3.13\n",
      "Optax Version: 0.1.2\n",
      " Flax Version: 0.5.2\n",
      "Found 8 devices.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import jax\n",
    "from jax import numpy as jnp, random\n",
    "\n",
    "from itertools import chain\n",
    "from typing import Callable\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from flax.training import train_state\n",
    "from flax import traverse_util\n",
    "import flax\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, FlaxAutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "\n",
    "print(\"  JAX Version:\", jax.__version__)\n",
    "print(\"Optax Version: {}\".format(optax.__version__))\n",
    "print(\" Flax Version: {}\".format(flax.__version__))\n",
    "devices = jax.local_devices()\n",
    "print(f\"Found {len(devices)} devices.\")\n",
    "devices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0836c9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
       " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
       " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
       " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
       " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14eb87",
   "metadata": {},
   "source": [
    "# Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9d7c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    nb_epochs = 5\n",
    "    lr = 2e-5\n",
    "    per_device_bs = 4\n",
    "    num_labels = 5\n",
    "    model_name = 'bert-base-uncased'\n",
    "    total_batch_size = per_device_bs * jax.local_device_count()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02540d",
   "metadata": {},
   "source": [
    "# Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd49f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_acc(preds, labels):\n",
    "    assert len(preds) == len(labels), \"Predictions and Labels matrices must be of same length\"\n",
    "    acc = (preds == labels).sum() / len(preds)\n",
    "    return acc\n",
    "\n",
    "class ACCURACY(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=\"Calculates Accuracy metric.\",\n",
    "            citation=\"TODO: _CITATION\",\n",
    "            inputs_description=\"_KWARGS_DESCRIPTION\",\n",
    "            features=datasets.Features({\n",
    "                'predictions': datasets.Value('int64'),\n",
    "                'references': datasets.Value('int64'),\n",
    "            }),\n",
    "            codebase_urls=[],\n",
    "            reference_urls=[],\n",
    "            format='numpy'\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references):\n",
    "        return {\"ACCURACY\": simple_acc(predictions, references)}\n",
    "    \n",
    "metric = ACCURACY()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa881f",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97130c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BBC News train dataset of shape 2,002 x 3.\n",
      "Loaded BBC News test dataset of shape 223 x 3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>worcester v sale (fri) sixways  friday  25 feb...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>sociedad set to rescue mladenovic rangers are ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>robots march to us cinema summit animated movi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>stam spices up man utd encounter ac milan defe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>campaigners attack mtv  sleaze  mtv has been c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  label\n",
       "0          sport  worcester v sale (fri) sixways  friday  25 feb...      3\n",
       "1          sport  sociedad set to rescue mladenovic rangers are ...      3\n",
       "2  entertainment  robots march to us cinema summit animated movi...      1\n",
       "3          sport  stam spices up man utd encounter ac milan defe...      3\n",
       "4  entertainment  campaigners attack mtv  sleaze  mtv has been c...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category2label = {\n",
    "    'business':0,\n",
    "    'entertainment':1,\n",
    "    'politics':2,\n",
    "    'sport':3,\n",
    "    'tech':4\n",
    "}\n",
    "\n",
    "path = '/home/rflagg/data/BBC-News/train-df.csv'\n",
    "train_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded BBC News train dataset of shape {train_df.shape[0]:,d} x {train_df.shape[1]:,d}.\")\n",
    "\n",
    "path = '/home/rflagg/data/BBC-News/test-df.csv'\n",
    "test_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded BBC News test dataset of shape {test_df.shape[0]:,d} x {test_df.shape[1]:,d}.\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdce708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-3d8409af66a33404\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/rflagg/.cache/huggingface/datasets/csv/default-3d8409af66a33404/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2beeb4b6266e4907b1fe59adc2405f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-b00eaff491008f02\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/rflagg/.cache/huggingface/datasets/csv/default-b00eaff491008f02/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366f4d0c06cb417d88b01a6aaffc2483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the training and testing files loaded in HF dataset format\n",
    "raw_train = load_dataset(\"csv\", data_files={'train': ['/home/rflagg/data/BBC-News/train-df.csv']})\n",
    "raw_test = load_dataset(\"csv\", data_files={'test': ['/home/rflagg/data/BBC-News/test-df.csv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565e201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'function'=<function preprocess_function at 0x7fb32699f820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3f0534446147cbab854c53d7c6193c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818af15c4dda44a490ab335f8a8e5162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(data):\n",
    "    \"\"\"\n",
    "    Preprocessing function\n",
    "    \"\"\"\n",
    "    texts = (data[\"text\"],)\n",
    "    processed = Config.tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n",
    "    processed[\"labels\"] = data[\"label\"]\n",
    "    return processed\n",
    "\n",
    "train_dataset = raw_train.map(preprocess_function, batched=True, remove_columns=raw_train[\"train\"].column_names)\n",
    "test_dataset = raw_test.map(preprocess_function, batched=True, remove_columns=raw_test['test'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31df310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'> 2002 223\n"
     ]
    }
   ],
   "source": [
    "train = train_dataset['train']\n",
    "valid = test_dataset['test']\n",
    "print(type(train), len(train), len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3100bc3",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc098ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('classifier', 'kernel'), ('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('classifier', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(Config.model_name, num_labels=Config.num_labels)\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(Config.model_name, config=config, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7939c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train steps (all the epochs) is 310\n"
     ]
    }
   ],
   "source": [
    "num_train_steps = len(train) // Config.total_batch_size * Config.nb_epochs\n",
    "learning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, peak_value=Config.lr, pct_start=0.1)\n",
    "print(\"The number of train steps (all the epochs) is\", num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224a366",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccdd0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adamw(learning_rate=Config.lr, b1=0.9, b2=0.999, eps=1e-6, weight_decay=1e-2)\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    loss = optax.softmax_cross_entropy(logits, onehot(targets, num_classes=Config.num_labels))\n",
    "    return jnp.mean(loss)\n",
    "\n",
    "def eval_fn(logits): return logits.argmax(-1)\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    eval_function: Callable = flax.struct.field(pytree_node=False)\n",
    "    loss_function: Callable = flax.struct.field(pytree_node=False)\n",
    "        \n",
    "state = TrainState.create(\n",
    "    apply_fn = model.__call__,\n",
    "    params = model.params,\n",
    "    tx = optimizer,\n",
    "    eval_function=eval_fn,\n",
    "    loss_function=loss_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c9ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbcTrainDataLoader(rng, dataset, batch_size, do_shard=False):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        if do_shard: batch = shard(batch)\n",
    "\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2e72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbcEvalDataLoader(dataset, batch_size, do_shard=False):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        if do_shard: batch = shard(batch)\n",
    "\n",
    "        yield batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86130771",
   "metadata": {},
   "source": [
    "# Parallel Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2059c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "    \n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_fn(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = jax.lax.pmean({'loss': loss, 'learning_rate': learning_rate_function(state.step)}, axis_name='batch')\n",
    "    \n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec453e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a58266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.eval_function(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a0b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c330f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = flax.jax_utils.replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a54dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27333375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 13:38:58.236237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 26.1 s, total: 3min 6s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rng, input_rng = jax.random.split(rng)\n",
    "for batch in bbcTrainDataLoader(input_rng, train, Config.total_batch_size, do_shard=True):\n",
    "    state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "    break\n",
    "for batch in bbcEvalDataLoader(valid, Config.total_batch_size, do_shard=True):\n",
    "    labels = batch.pop(\"labels\")\n",
    "    predictions = parallel_eval_step(state, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49a53234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71110583a1ee4ecfb7b7bfd4989ad7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 | Train loss: 0.084 | Eval ACCURACY: 0.979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/5 | Train loss: 0.008 | Eval ACCURACY: 0.974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 | Train loss: 0.004 | Eval ACCURACY: 0.974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/5 | Train loss: 0.005 | Eval ACCURACY: 0.984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 | Train loss: 0.003 | Eval ACCURACY: 0.984\n",
      "CPU times: user 1min 6s, sys: 12.1 s, total: 1min 18s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i, epoch in enumerate(tqdm(range(1, Config.nb_epochs + 1), desc=f\"Epoch...\", position=0, leave=True)):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(total=len(train) // Config.total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "        for batch in bbcTrainDataLoader(input_rng, train, Config.total_batch_size, do_shard=True):\n",
    "            state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(total=len(valid) // Config.total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "        for batch in bbcEvalDataLoader(valid, Config.total_batch_size, do_shard=True):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = parallel_eval_step(state, batch)\n",
    "            metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n",
    "    eval_score = round(list(eval_metric.values())[0], 3)\n",
    "    metric_name = list(eval_metric.keys())[0]\n",
    "    \n",
    "    print(f\"{i+1}/{Config.nb_epochs} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b176d",
   "metadata": {},
   "source": [
    "## On One Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b39ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "    \n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_fn(state.params)\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = {'loss': loss, 'learning_rate': learning_rate_function(state.step)}\n",
    "    \n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_train_step = jax.jit(train_step, donate_argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.eval_function(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_eval_step = jax.jit(eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ffade",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "rng, dropout_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e43e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in bbcEvalDataLoader(valid, Config.total_batch_size, do_shard=False):break\n",
    "labels = batch.pop(\"labels\")\n",
    "predictions = jit_eval_step(state, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303a409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, input_rng = jax.random.split(rng)\n",
    "for batch in bbcTrainDataLoader(input_rng, train, Config.total_batch_size):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "    \n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_fn(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = jax.lax.pmean({'loss': loss, 'learning_rate': learning_rate_function(state.step)}, axis_name='batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7736704",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets = batch.pop(\"labels\")\n",
    "dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "\n",
    "def loss_function(params):\n",
    "    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "    loss = state.loss_function(logits, targets)\n",
    "    return loss\n",
    "\n",
    "grad_fn = jax.value_and_grad(loss_function)\n",
    "loss, grad = grad_fn(state.params)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7f393",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch.keys()\n",
    "state, train_metrics, dropout_rng = jit_train_step(state, batch, dropout_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c999d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i, epoch in enumerate(tqdm(range(1, Config.nb_epochs + 1), desc=f\"Epoch...\", position=0, leave=True)):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(total=len(train) // Config.total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "        for batch in bbcTrainDataLoader(input_rng, train, Config.total_batch_size, do_shard=False):\n",
    "            state, train_metrics, dropout_rng = jit_train_step(state, batch, dropout_rng)\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(total=len(valid) // Config.total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "        for batch in bbcEvalDataLoader(valid, Config.total_batch_size, do_shard=False):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = jit_eval_step(state, batch)\n",
    "            metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n",
    "    eval_score = round(list(eval_metric.values())[0], 3)\n",
    "    metric_name = list(eval_metric.keys())[0]\n",
    "    \n",
    "    print(f\"{i+1}/{Config.nb_epochs} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efaa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "split_nb = int(len(df) * 0.10)\n",
    "\n",
    "test_df = df[:split_nb].reset_index(drop=True)\n",
    "train_df = df[split_nb:].reset_index(drop=True)\n",
    "\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-test-df.csv'\n",
    "test_df.to_csv(path, index=False)\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-train-df.csv'\n",
    "train_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-train-df.csv'\n",
    "train_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded HAM/SPAM train dataset of shape {train_df.shape[0]:,d} x {train_df.shape[1]:,d}.\")\n",
    "\n",
    "path = '/home/rflagg/data/ham-spam/ham-spam-test-df.csv'\n",
    "test_df = pd.read_csv(path, na_filter=False)\n",
    "print(f\"Loaded HAM/SPAM test dataset of shape {test_df.shape[0]:,d} x {test_df.shape[1]:,d}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30867cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ea1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = '/home/rflagg/data/ham-spam/SMSSpamCollection'\n",
    "df = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
    "with open(file_path) as f:\n",
    "  for line in f.readlines():\n",
    "    split = line.split('\\t')\n",
    "    df = df.append({'label': 1 if split[0] == 'spam' else 0,\n",
    "                    'text': split[1]},\n",
    "                    ignore_index = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9256216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d387c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/home/rflagg/data/training.1600000.processed.noemoticon.csv\"\n",
    "df = pd.read_csv(path, encoding='latin-1', names=['sentiment', 'id', 'date', 'query', 'username', 'text'])\n",
    "df = df[['sentiment', 'text']]\n",
    "df['sentiment'] = df['sentiment'].map({4: 1, 0: 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.sample(n=1).iloc[0]\n",
    "f\"[{x.sentiment}] {x.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_and_save(file_path: str, split: float = 0.10):\n",
    "    file = pd.read_csv(file_path, encoding='latin-1', names=['sentiment', 'id', 'date', 'query', 'username', 'text'])\n",
    "    file = file[['sentiment', 'text']]\n",
    "    file['sentiment'] = file['sentiment'].map({4: 1, 0: 0})\n",
    "    \n",
    "    file = file.sample(frac=1).reset_index(drop=True)\n",
    "    split_nb = int(len(file) * split)\n",
    "    \n",
    "    test_set = file[:split_nb].reset_index(drop=True)\n",
    "    train_set = file[split_nb:].reset_index(drop=True)\n",
    "    \n",
    "    train_set.to_csv(\"train_file.csv\", index=None)\n",
    "    test_set.to_csv(\"test_file.csv\", index=None)\n",
    "    print(\"Done.\")\n",
    "\n",
    "split_and_save(\"/home/rflagg/data/training.1600000.processed.noemoticon.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27622d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "request = requests.get(\"https://drive.google.com/uc?export=download&id=1wHt8PsMLsfX5yNSqrt2fSTcb8LEiclcf\")\n",
    "with open(\"data.zip\", \"wb\") as file:\n",
    "    file.write(request.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "CONFIG = dict(\n",
    "    lr=2e-5,\n",
    "    model_name = 'bert-base-uncased',\n",
    "    epochs = 5,\n",
    "    split = 0.10,\n",
    "    per_device_bs = 4,\n",
    "    seed = 42,\n",
    "    num_labels = 5,\n",
    "    infra = \"Kaggle\",\n",
    "    competition = 'none',\n",
    "    _wandb_kernel = 'tanaym'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5087be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, stratify = df.category, test_size=1/10, random_state=42)\n",
    "path = '/home/rflagg/data/BBC-News/train-df.csv'\n",
    "train_df.to_csv(path, index=False)\n",
    "\n",
    "path = '/home/rflagg/data/BBC-News/test-df.csv'\n",
    "test_df.to_csv(path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
