{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b969cf",
   "metadata": {},
   "source": [
    "- [Text Classification Using Flax (JAX) Networks](https://coderzcolumn.com/tutorials/artificial-intelligence/text-classification-using-flax-jax-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170f2763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae0c49",
   "metadata": {},
   "source": [
    "# Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20782bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"b1\":0.9, \n",
    "    \"b2\":0.999, \n",
    "    \"dataset\":\"sst2\", # BBC-News, sst2\n",
    "    \"eps\":1e-6,\n",
    "    \"learning-rate\":2e-5,\n",
    "    \"model\":\"bert-base-cased\",\n",
    "    \"model-directory\":f\"/home/rflagg/model/sst2\",\n",
    "    \"number-of-epochs\":3,\n",
    "    \"number-of-labels\":2,\n",
    "    \"train-in-parallel\":False,\n",
    "    \"per-device-batch-size\":4,\n",
    "    \"seed\":0,\n",
    "    \"weight-decay\":1e-2,\n",
    "    \"text-key\":\"sentence\",  # text for BBC-News; sentence for sst2\n",
    "    \"label-key\":\"label\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48231d3f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ed2d297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-3c53501a961beae2\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/rflagg/.cache/huggingface/datasets/csv/default-3c53501a961beae2/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba4a03b76e346309783a4544adcf62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "directory = f\"/home/rflagg/data/{CONFIG['dataset']}\"\n",
    "\n",
    "if CONFIG['dataset'] == \"BBC-News\":   \n",
    "    dataset = load_dataset(\n",
    "        'csv', \n",
    "        data_files={\n",
    "            'train': f\"{directory}/train-df.csv\", \n",
    "             'validation': f\"{directory}/test-df.csv\"\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    dataset = load_dataset(\n",
    "        'csv', \n",
    "        data_files={\n",
    "            'train': f\"{directory}/train-df.csv\", \n",
    "            'test': f\"{directory}/test-df.csv\", \n",
    "            'validation': f\"{directory}/validation-df.csv\"\n",
    "        }\n",
    "    )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d69db",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58e1a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['model'])\n",
    "\n",
    "def preprocess_function(data, text_key=CONFIG[\"text-key\"], label_key=CONFIG[\"label-key\"]):\n",
    "    texts = (data[text_key],)\n",
    "    processed = tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n",
    "    processed[\"labels\"] = data[label_key]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68d3f360",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09b937828c143b49340c1cb199891b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356d7bec06c241f2a65a25ab9c5d5567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d40a5e109845cf8d0d6efda5e62aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized = dataset.map(\n",
    "    preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb26c22e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds = dataset_tokenized[\"train\"]\n",
    "validation_ds = dataset_tokenized[\"validation\"]\n",
    "if CONFIG['dataset'] == \"sst2\": test_ds = dataset_tokenized[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909204f",
   "metadata": {},
   "source": [
    "# Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89bdc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "metric = load_metric('glue', \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class F1EtcMetric(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=\"Calculates precision, recall, f1 score, and support.\",\n",
    "            citation=\"TODO: _CITATION\",\n",
    "            inputs_description=\"_KWARGS_DESCRIPTION\",\n",
    "            features=datasets.Features({\n",
    "                'predictions': datasets.Value('int64'),\n",
    "                'references': datasets.Value('int64'),\n",
    "            }),\n",
    "            codebase_urls=[],\n",
    "            reference_urls=[],\n",
    "            format='numpy'\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references):\n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(references, predictions, average='weighted')\n",
    "        return {\n",
    "            \"precision\":precision,\n",
    "            \"recall\":recall,\n",
    "            \"f1\":fscore\n",
    "        }\n",
    "    \n",
    "metric = F1EtcMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1a91c",
   "metadata": {},
   "source": [
    "# Fine-tune the model\n",
    "\n",
    "- [Huggingface Evaluate](https://huggingface.co/docs/evaluate/index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55791e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from itertools import chain\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import FlaxAutoModelForSequenceClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f10fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: {('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('classifier', 'bias'), ('classifier', 'kernel')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(CONFIG['model'], num_labels=CONFIG[\"number-of-labels\"])\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(CONFIG['model'], config=config, seed=CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26fbbfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall batch size (both for training and eval) is 4\n"
     ]
    }
   ],
   "source": [
    "total_batch_size = CONFIG['per-device-batch-size']\n",
    "if CONFIG['train-in-parallel']: total_batch_size *= jax.local_device_count()\n",
    "print(\"The overall batch size (both for training and eval) is\", total_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e05c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = len(train_ds) // total_batch_size * CONFIG['number-of-epochs']\n",
    "learning_rate_function = optax.linear_schedule(init_value=CONFIG['learning-rate'], end_value=0, transition_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b022fc9",
   "metadata": {},
   "source": [
    "## Defining the training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840887f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax.training import train_state\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3ed58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    logits_function: Callable = flax.struct.field(pytree_node=False)\n",
    "    loss_function: Callable = flax.struct.field(pytree_node=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0393645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_mask_fn(params):\n",
    "    flat_params = flax.traverse_util.flatten_dict(params)\n",
    "    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n",
    "    return flax.traverse_util.unflatten_dict(flat_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01bbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamw(weight_decay):\n",
    "    return optax.adamw(\n",
    "        learning_rate=learning_rate_function, b1=CONFIG['b1'], b2=CONFIG['b2'], eps=CONFIG['eps'], weight_decay=weight_decay, mask=decay_mask_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37da52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(logits, labels):\n",
    "    xentropy = optax.softmax_cross_entropy(logits, onehot(labels, num_classes=CONFIG['number-of-labels']))\n",
    "    return jnp.mean(xentropy)\n",
    "     \n",
    "def eval_function(logits): return logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad4d1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=adamw(weight_decay=CONFIG['weight-decay']),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f395c5",
   "metadata": {},
   "source": [
    "## Defining the training and evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "725cd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng, train_in_parallel=CONFIG['train-in-parallel']):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "\n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    grad_function = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_function(state.params)\n",
    "    if train_in_parallel:\n",
    "        grad = jax.lax.pmean(grad, \"batch\")\n",
    "        new_state = state.apply_gradients(grads=grad)\n",
    "        metrics = jax.lax.pmean({\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}, axis_name=\"batch\")\n",
    "    else:\n",
    "        new_state = state.apply_gradients(grads=grad)\n",
    "        metrics = {\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}\n",
    "        \n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43271f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.logits_function(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf7031",
   "metadata": {},
   "source": [
    "## Defining the data collators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f456fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(rng, dataset, batch_size, train_in_parallel=CONFIG['train-in-parallel']):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        if train_in_parallel: batch = shard(batch)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccabe92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_data_loader(dataset, batch_size, train_in_parallel=CONFIG['train-in-parallel']):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        if train_in_parallel: batch = shard(batch)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219ecef",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6527f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_train_step = jax.jit(train_step, donate_argnums=(0,))\n",
    "jit_eval_step = jax.jit(eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73632127",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(CONFIG['seed'])\n",
    "rng, dropout_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30d9df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "for batch in train_data_loader(input_rng, train_ds, total_batch_size):\n",
    "    state, train_metrics, dropout_rngs = jit_train_step(state, batch, dropout_rng)\n",
    "    break\n",
    "for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "    labels = batch.pop(\"labels\")\n",
    "    predictions = jit_eval_step(state, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5417e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "    labels = batch.pop(\"labels\")\n",
    "    predictions = jit_eval_step(state, batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d849da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=len(validation_ds) // total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "    for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "        labels = batch.pop(\"labels\")\n",
    "        predictions = jit_eval_step(state, batch)\n",
    "        metric.add_batch(predictions=predictions, references=labels)\n",
    "        progress_bar_eval.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e250d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.add_batch(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbdc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = metric.compute()\n",
    "\n",
    "loss = round(train_metrics['loss'].item(), 4)\n",
    "eval_score = round(list(eval_metric.values())[0], 4)\n",
    "metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "print(f\"{i+1}/{CONFIG['number-of-epochs']} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee02d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = metric.compute()\n",
    "loss = round(train_metrics['loss'].item(), 4)\n",
    "eval_score = round(list(eval_metric.values())[0], 4)\n",
    "metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "print(f\"{i+1}/{CONFIG['number-of-epochs']} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11450e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flax\n",
    "flax.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6186bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaa7494c5b44faaa3422c3657d81a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch ...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/16837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 | Train loss: 0.0077 | Eval accuracy: 0.9209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/16837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/3 | Train loss: 0.0325 | Eval accuracy: 0.9163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/16837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 | Train loss: 0.0009 | Eval accuracy: 0.9232\n",
      "CPU times: user 14min 18s, sys: 2min 47s, total: 17min 5s\n",
      "Wall time: 26min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, epoch in enumerate(tqdm(range(1, CONFIG['number-of-epochs'] + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(total=len(train_ds) // total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "        for batch in train_data_loader(input_rng, train_ds, total_batch_size):\n",
    "            state, train_metrics, dropout_rng = jit_train_step(state, batch, dropout_rng)\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(total=len(validation_ds) // total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "        for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = jit_eval_step(state, batch)\n",
    "            metric.add_batch(predictions=predictions, references=labels)\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(train_metrics['loss'].item(), 4)\n",
    "    eval_score = round(list(eval_metric.values())[0], 4)\n",
    "    metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "    print(f\"{i+1}/{CONFIG['number-of-epochs']} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94aa93",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1134e3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rflagg/model/sst2/tokenizer_config.json',\n",
       " '/home/rflagg/model/sst2/special_tokens_map.json',\n",
       " '/home/rflagg/model/sst2/vocab.txt',\n",
       " '/home/rflagg/model/sst2/added_tokens.json',\n",
       " '/home/rflagg/model/sst2/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(CONFIG['model-directory'])\n",
    "model.save_pretrained(CONFIG['model-directory'], state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4d272ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8f5d8a3c0d4dfcaf1a53aa47d532ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate on test data\n",
    "metric = load_metric('glue', \"sst2\")\n",
    "with tqdm(total=len(validation_ds) // total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "    for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "        labels = batch.pop(\"labels\")\n",
    "        predictions = jit_eval_step(state, batch)\n",
    "        metric.add_batch(predictions=predictions, references=labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "909ea1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['model-directory'])\n",
    "config = AutoConfig.from_pretrained(CONFIG['model-directory'], num_labels=CONFIG[\"number-of-labels\"])\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(CONFIG['model-directory'], config=config, seed=CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55e7a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=adamw(weight_decay=CONFIG['weight-decay']),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9d28683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9232\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test data\n",
    "metric = load_metric('glue', \"sst2\")\n",
    "with tqdm(total=len(validation_ds) // total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "    for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "        labels = batch.pop(\"labels\")\n",
    "        predictions = jit_eval_step(state, batch)\n",
    "        metric.add_batch(predictions=predictions, references=labels)\n",
    "        progress_bar_eval.update(1)\n",
    "\n",
    "test_metric = metric.compute()\n",
    "\n",
    "test_score = round(list(test_metric.values())[0], 4)\n",
    "metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "print(f\"Test {metric_name}: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ad6aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_set, batch_size=2)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# loaded_model.to(device)\n",
    "\n",
    "predictions_total = []\n",
    "labels_total = []\n",
    "probabilities_total=[]\n",
    "probability_total=[]\n",
    "threshold=0.93\n",
    "with torch.no_grad():\n",
    "    loaded_model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loaded_model.to(device)\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        # get the inputs;\n",
    "        labels = batch[\"labels\"]\n",
    "        del batch[\"labels\"]\n",
    "\n",
    "        # move everything to the GPU\n",
    "        for k,v in batch.items(): batch[k] = batch[k].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = loaded_model(**batch)\n",
    "        logits = outputs.logits\n",
    "        probabilities = logits.softmax(dim=-1).detach().cpu().numpy()\n",
    "        probability= [max(x) for x in probabilities]\n",
    "        predictions = logits.argmax(-1).tolist()\n",
    "        predictions= [y if x>threshold else 0 for x,y in zip(probability, predictions)]\n",
    "        probability_total.extend(probability)\n",
    "        probabilities_total.extend(probabilities.tolist())\n",
    "        predictions_total.extend(predictions)\n",
    "        labels_total.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b3b87",
   "metadata": {},
   "source": [
    "## Parallel Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))\n",
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")\n",
    "state = flax.jax_utils.replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e246de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(CONFIG['seed'])\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "for batch in train_data_loader(input_rng, train_ds, total_batch_size):\n",
    "    state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "    break\n",
    "for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "    labels = batch.pop(\"labels\")\n",
    "    predictions = parallel_eval_step(state, batch)\n",
    "    metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n",
    "    eval_metric = metric.compute()\n",
    "    print(eval_metric)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96697350",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, epoch in enumerate(tqdm(range(1, CONFIG['number-of-epochs'] + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(total=len(train_ds) // total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "        for batch in train_data_loader(input_rng, train_ds, total_batch_size):\n",
    "            state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(total=len(validation_ds) // total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "        for batch in eval_data_loader(validation_ds, total_batch_size):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = parallel_eval_step(state, batch)\n",
    "            metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 4)\n",
    "    #eval_score = round(list(eval_metric.values())[2], 4)\n",
    "    #metric_name = list(eval_metric.keys())[2]\n",
    "    eval_score = round(list(eval_metric.values())[0], 4)\n",
    "    metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "    print(f\"{i+1}/{CONFIG['number-of-epochs']} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "#import gc\n",
    "\n",
    "all_categories = ['alt.atheism','comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware',\n",
    "                  'comp.sys.mac.hardware','comp.windows.x', 'misc.forsale','rec.autos','rec.motorcycles',\n",
    "                  'rec.sport.baseball','rec.sport.hockey','sci.crypt','sci.electronics','sci.med',\n",
    "                  'sci.space','soc.religion.christian','talk.politics.guns','talk.politics.mideast',\n",
    "                  'talk.politics.misc','talk.religion.misc']\n",
    "\n",
    "selected_categories = ['comp.sys.mac.hardware','comp.windows.x','rec.motorcycles','sci.crypt','talk.politics.mideast']\n",
    "\n",
    "X_train_text, Y_train = datasets.fetch_20newsgroups(subset=\"train\", categories=selected_categories, return_X_y=True)\n",
    "X_test_text , Y_test  = datasets.fetch_20newsgroups(subset=\"test\", categories=selected_categories, return_X_y=True)\n",
    "\n",
    "X_train_text = np.array(X_train_text)\n",
    "X_test_text = np.array(X_test_text)\n",
    "\n",
    "classes = np.unique(Y_train)\n",
    "mapping = dict(zip(classes, selected_categories))\n",
    "\n",
    "len(X_train_text), len(X_test_text), classes, mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from jax import numpy as jnp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=50000)\n",
    "\n",
    "vectorizer.fit(np.concatenate((X_train_text, X_test_text)))\n",
    "X_train = vectorizer.transform(X_train_text)\n",
    "X_test = vectorizer.transform(X_test_text)\n",
    "\n",
    "X_train = jnp.array(X_train.toarray(), dtype=jnp.float16)\n",
    "X_test  = jnp.array(X_test.toarray(), dtype=jnp.float16)\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea93ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen\n",
    "from jax import random\n",
    "\n",
    "class TextClassifier(linen.Module):\n",
    "    def setup(self):\n",
    "        self.linear1 = linen.Dense(features=128, name=\"DENSE1\")\n",
    "        self.linear2 = linen.Dense(features=64, name=\"DENSE2\")\n",
    "        self.linear3 = linen.Dense(len(classes), name=\"DENSE3\")\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = linen.relu(self.linear1(inputs))\n",
    "        x = linen.relu(self.linear2(x))\n",
    "        logits = self.linear3(x)\n",
    "\n",
    "        return logits #linen.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = jax.random.PRNGKey(0)\n",
    "\n",
    "model = TextClassifier()\n",
    "params = model.init(seed, X_train[:5])\n",
    "\n",
    "for layer_params in params[\"params\"].items():\n",
    "    print(\"Layer Name : {}\".format(layer_params[0]))\n",
    "    weights, biases = layer_params[1][\"kernel\"], layer_params[1][\"bias\"]\n",
    "    print(\"\\tLayer Weights : {}, Biases : {}\".format(weights.shape, biases.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.apply(params, X_train[:5])\n",
    "\n",
    "preds.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1841dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropyLoss(weights, input_data, actual):\n",
    "    logits_preds = model.apply(weights, input_data)\n",
    "    one_hot_actual = jax.nn.one_hot(actual, num_classes=len(classes))\n",
    "    return optax.softmax_cross_entropy(logits=logits_preds, labels=one_hot_actual).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import value_and_grad\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def TrainModelInBatches(X, Y, X_val, Y_val, epochs, weights, optimizer_state, batch_size=32):\n",
    "    for i in range(1, epochs+1):\n",
    "        batches = jnp.arange((X.shape[0]//batch_size)+1) ### Batch Indices\n",
    "\n",
    "        losses = [] ## Record loss of each batch\n",
    "        for batch in tqdm(batches):\n",
    "            if batch != batches[-1]:\n",
    "                start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n",
    "            else:\n",
    "                start, end = int(batch*batch_size), None\n",
    "\n",
    "            X_batch, Y_batch = X[start:end], Y[start:end] ## Single batch of data\n",
    "\n",
    "            loss, gradients = value_and_grad(CrossEntropyLoss)(weights, X_batch,Y_batch)\n",
    "\n",
    "            ## Update Weights\n",
    "            updates, optimizer_state = optimizer.update(gradients, optimizer_state)\n",
    "            weights = optax.apply_updates(weights, updates)\n",
    "\n",
    "            losses.append(loss) ## Record Loss\n",
    "\n",
    "        print(\"CrossEntropyLoss : {:.3f}\".format(jnp.array(losses).mean()))\n",
    "\n",
    "        Y_val_preds = model.apply(weights, X_val)\n",
    "        val_acc = accuracy_score(Y_val, jnp.argmax(Y_val_preds, axis=1))\n",
    "        print(\"Validation  Accuracy : {:.3f}\".format(val_acc))\n",
    "\n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe04cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.PRNGKey(0)\n",
    "batch_size=256\n",
    "epochs=8\n",
    "learning_rate = jnp.array(1/1e3)\n",
    "\n",
    "model = TextClassifier()\n",
    "weights = model.init(seed, X_train[:5])\n",
    "\n",
    "optimizer = optax.adam(learning_rate=learning_rate)\n",
    "optimizer_state = optimizer.init(weights)\n",
    "\n",
    "final_weights = TrainModelInBatches(X_train, Y_train, X_test, Y_test, epochs, weights, optimizer_state, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221c43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
